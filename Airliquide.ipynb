{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHROzvb6RR_B"
   },
   "source": [
    "Let's setup Spark on your Colab environment. Run the cell below!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JMAP97VRPJc",
    "outputId": "e208695d-ef25-4245-946e-6437cb03a330",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from pyspark) (0.10.9)\n",
      "Requirement already satisfied: keras in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from keras) (1.6.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from keras) (1.20.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: six in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already satisfied: scikit-surprise in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from scikit-surprise) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from scikit-surprise) (1.20.3)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from scikit-surprise) (1.6.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (from scikit-surprise) (1.15.0)\n",
      "Requirement already satisfied: findspark in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: wget in c:\\users\\ngani\\anaconda3\\envs\\mlenv\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install -U -q PyDrive\n",
    "!pip install keras\n",
    "!pip install scikit-surprise\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "!pip install findspark\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HPRcHRTOOYGM",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark import SparkConf, SparkContext, sql\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import findspark\n",
    "findspark.add_packages('mysql:mysql-connector-java:8.0.11')\n",
    "import keras\n",
    "import os.path\n",
    "from os import path\n",
    "from zipfile import ZipFile\n",
    "import wget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6I5Nx1YW2NG"
   },
   "source": [
    "# **1. Download the movie lens dataset and extract** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVWN2wl0Rl2X",
    "outputId": "2a9686a2-826e-411e-b1fb-60d1231f2e15",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exist. No need to download \n"
     ]
    }
   ],
   "source": [
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "dataset_path = \"dataset/\"\n",
    "\n",
    "if not path.exists(dataset_path):\n",
    "    !mkdir dataset\n",
    "    #!wget -P dataset/ https://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
    "    #data_url = \"https://files.grouplens.org/datasets/movielens/ml-25m.zip\"\n",
    "    data_url1 = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "    wget.download(data_url1, 'dataset/')\n",
    "else:\n",
    "  print(\"dataset already exist. No need to download \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XM0Urcd-XqNl",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lbbTsBYLXqsM",
    "outputId": "d607d157-48b5-4119-bc46-dbc36eb83eab",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset already exist. No need to extract \n"
     ]
    }
   ],
   "source": [
    "# Only extract the data the first time the script is run.\n",
    "movielens_dir = dataset_path + \"/ml-latest-small\"\n",
    "movielens_zipped_file = dataset_path + \"ml-latest-small.zip\"\n",
    "\n",
    "if not path.exists(movielens_dir):\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as z:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        z.extractall(path=dataset_path)\n",
    "        print(\"Done!\")\n",
    "else:\n",
    "   print(\"dataset already exist. No need to extract \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_dvBEIbfwad"
   },
   "source": [
    "# **2. Setup the big data environment with pyspark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QeO3m6r2fI_Q",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-7aa24d27afdd>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mconf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSparkConf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"spark.ui.port\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"4050\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m# create the context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0msc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconf\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mspark\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSparkSession\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pyspark\\context.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001B[0m\n\u001B[0;32m    142\u001B[0m                 \" is not allowed as it is a security risk.\")\n\u001B[0;32m    143\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 144\u001B[1;33m         \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_ensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgateway\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgateway\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconf\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    145\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001B[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pyspark\\context.py\u001B[0m in \u001B[0;36m_ensure_initialized\u001B[1;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[0;32m    329\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    330\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gateway\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 331\u001B[1;33m                 \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gateway\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgateway\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mlaunch_gateway\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    332\u001B[0m                 \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jvm\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSparkContext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_gateway\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjvm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    333\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pyspark\\java_gateway.py\u001B[0m in \u001B[0;36mlaunch_gateway\u001B[1;34m(conf, popen_kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m             \u001B[1;31m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    104\u001B[0m             \u001B[1;32mwhile\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mproc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn_info_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 105\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    106\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    107\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misfile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconn_info_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "# create the context\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Movie recommendation\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "NOnHeue9gIax",
    "outputId": "4e01c003-8f0f-42f0-eb14-6f4ba45fa9e7",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFViQ0YEgODU"
   },
   "source": [
    "# **3. Data exploration and cleaning**\n",
    "\n",
    "\n",
    "**a .Reading the downloaded movie dataset to pyspark dataframe**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratings_file = movielens_dir + \"/ratings.csv\"\n",
    "movies_file = movielens_dir + \"/movies.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSAwBblbgLFO",
    "outputId": "ac1b9fae-2759-42e8-d17a-f8c25c472589",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Define the dataset schema \n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "ratings_df_schema = StructType(\n",
    "  [StructField('userId', IntegerType()),\n",
    "   StructField('movieId', IntegerType()),\n",
    "   StructField('rating', DoubleType())]\n",
    ")\n",
    "movies_df_schema = StructType(\n",
    "  [StructField('movieId', IntegerType()),\n",
    "   StructField('title', StringType()),\n",
    "   StructField('genres', StringType())]\n",
    ")\n",
    "\n",
    "# creating the pyspark dataframes and cache in memory\n",
    "\n",
    "ratings_df = spark.read\\\n",
    "                  .options(header =True, inferSchema=False)\\\n",
    "                  .schema(ratings_df_schema)\\\n",
    "                  .csv(ratings_file)\n",
    "movies_df = spark.read\\\n",
    "                .options(header =True, inferSchema=False)\\\n",
    "                .schema(movies_df_schema)\\\n",
    "                .csv(movies_file)\n",
    "\n",
    "ratings_df.cache()\n",
    "movies_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oAFYqzShHuj",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratings_df.show(10, truncate=False)\n",
    "movies_df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KI_9mY4sm-xk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjGozDwbm8J2",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSuO9fgB_Y2p"
   },
   "source": [
    "# **4. Building the user-based collaborative filtering**\n",
    "\n",
    "\n",
    "\n",
    "> For the this project, we will use the SurPRISE (Simple Python RecommendatIon System Engine) library\n",
    "\n",
    "\n",
    "> This is because it is faster and has an integrated SVD algorithms, a Matrix factorization algoritms\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3gaKcH42qE2g",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries from Surprise package\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, SVDpp\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fWISV0w-EnFQ",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Surprise is only compatible with pandas. So we will convert the pyspark dataframes to pandas dataframes\n",
    "#ratings_df_pd =ratings_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6-MdkDSPEnPD",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratings_pd = pd.read_csv(ratings_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratings_pd = ratings_pd[['userId', 'movieId', 'rating']]\n",
    "movies_pd = pd.read_csv(movies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kkDyoI3YGY0l",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating\n",
       "0            1        1     4.0\n",
       "1            1        3     4.0\n",
       "2            1        6     4.0\n",
       "3            1       47     5.0\n",
       "4            1       50     5.0\n",
       "...        ...      ...     ...\n",
       "100831     610   166534     4.0\n",
       "100832     610   168248     5.0\n",
       "100833     610   168250     5.0\n",
       "100834     610   168252     5.0\n",
       "100835     610   170875     3.0\n",
       "\n",
       "[100836 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0f_GymXyGaqM",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId       int64\n",
       "movieId      int64\n",
       "rating     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHRaqc-PGas8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aSXf6o97EaGK",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8691  0.8740  0.8724  0.8767  0.8649  0.8714  0.0041  \n",
      "MAE (testset)     0.6667  0.6714  0.6743  0.6718  0.6630  0.6694  0.0041  \n",
      "Fit time          3.20    2.83    2.71    2.69    2.70    2.83    0.19    \n",
      "Test time         0.10    0.10    0.15    0.10    0.10    0.11    0.02    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.86905931, 0.87403258, 0.87240831, 0.87674671, 0.86490019]),\n",
       " 'test_mae': array([0.66665083, 0.67140472, 0.6742839 , 0.67176314, 0.66295676]),\n",
       " 'fit_time': (3.195455312728882,\n",
       "  2.833423376083374,\n",
       "  2.713743209838867,\n",
       "  2.685817003250122,\n",
       "  2.7037711143493652),\n",
       " 'test_time': (0.10372352600097656,\n",
       "  0.10372233390808105,\n",
       "  0.14561080932617188,\n",
       "  0.10272598266601562,\n",
       "  0.09973263740539551)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Reader library\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Load ratings dataset with Dataset library\n",
    "data = Dataset.load_from_df(ratings_pd, reader)\n",
    "\n",
    "\n",
    "svd = SVD(n_factors=50)\n",
    "#svd_plusplus = SVDpp(n_factors=50)\n",
    "\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a mean Root Mean Sqaure Error of 0.8714 which is more than good enough for our case. Let us now train on our dataset and arrive at predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "S4tc8M6kGsJg",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x20acf902490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the the training set and fit the model\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "svd.fit(trainset)  # old version use svd.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_names = dict()\n",
    "\n",
    "for idx, names in zip(movies_pd['movieId'], movies_pd['title']):\n",
    "    id_2_names[idx] = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_set(user_id):\n",
    "    \n",
    "    fill = trainset.global_mean\n",
    "    anti_testset = list()\n",
    "    u = trainset.to_inner_uid(user_id)\n",
    "    \n",
    "    # ur == users ratings\n",
    "    user_items = set([item_inner_id for (item_inner_id, rating) in trainset.ur[u]])\n",
    "    \n",
    "    anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
    "                            i in trainset.all_items() if i not in user_items]\n",
    "    \n",
    "    return anti_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create a fuction to implement a top 10 movies rated by a user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_recommendations(user_id, num_recommender=10):\n",
    "    \n",
    "    testSet = create_test_set(user_id)\n",
    "    predict = svd.test(testSet)  # we can change to SVD++ later\n",
    "    \n",
    "    recommendation = list()\n",
    "    \n",
    "    for userID, movieID, actualRating, estimatedRating, _ in predict:\n",
    "        intMovieID = int(movieID)\n",
    "        recommendation.append((intMovieID, estimatedRating))\n",
    "        \n",
    "    recommendation.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    movie_names = []\n",
    "    movie_ratings = []\n",
    "    \n",
    "    for name, ratings in recommendation[:20]:\n",
    "        movie_names.append(id_2_names[name])\n",
    "        movie_ratings.append(ratings)\n",
    "        \n",
    "    movie_dataframe =  pd.DataFrame({'movie_names': movie_names,\n",
    "                                     'rating': movie_ratings})\n",
    "    \n",
    "    \n",
    "    return movie_dataframe.sort_values('rating', ascending=False)[['movie_names', 'rating']].head(num_recommender)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_names</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>4.394664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Avengers, The (2012)</td>\n",
       "      <td>4.094646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jaws (1975)</td>\n",
       "      <td>4.084902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cool Hand Luke (1967)</td>\n",
       "      <td>4.084296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Departed, The (2006)</td>\n",
       "      <td>4.070869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Grand Day Out with Wallace and Gromit, A (1989)</td>\n",
       "      <td>4.067885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In Bruges (2008)</td>\n",
       "      <td>4.049651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wallace &amp; Gromit: The Wrong Trousers (1993)</td>\n",
       "      <td>4.046354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Godfather: Part II, The (1974)</td>\n",
       "      <td>4.044107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Army of Darkness (1993)</td>\n",
       "      <td>4.036432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       movie_names    rating\n",
       "0           One Flew Over the Cuckoo's Nest (1975)  4.394664\n",
       "1                             Avengers, The (2012)  4.094646\n",
       "2                                      Jaws (1975)  4.084902\n",
       "3                            Cool Hand Luke (1967)  4.084296\n",
       "4                             Departed, The (2006)  4.070869\n",
       "5  Grand Day Out with Wallace and Gromit, A (1989)  4.067885\n",
       "6                                 In Bruges (2008)  4.049651\n",
       "7      Wallace & Gromit: The Wrong Trousers (1993)  4.046354\n",
       "8                   Godfather: Part II, The (1974)  4.044107\n",
       "9                          Army of Darkness (1993)  4.036432"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let us simulate the top 10 movies recommended movies for user 600\n",
    "\n",
    "top_recommendations(600, num_recommender=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q2ajZeL3GtSu",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset()\n",
    "\n",
    "predictions_svd = svd.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD - RMSE: 0.48725238724656844\n",
      "SVD - MAE: 0.37719565898840046\n"
     ]
    }
   ],
   "source": [
    "print('SVD - RMSE:', accuracy.rmse(predictions_svd, verbose=False))\n",
    "print('SVD - MAE:', accuracy.mae(predictions_svd, verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above evaluation metrics, the model obtained an RMSE of 0.4872 during the testing phase which is pretty good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model on a user\n",
    "Now let's use SVD to predict the rating that User with ID 500 will give to a random movie (let's say with Movie ID 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=500, iid=100, r_ui=None, est=2.6362786014980713, details={'was_impossible': False})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(500, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For movie with ID 100, I get an estimated prediction of 2.6362. The recommender system works purely on the basis of an assigned movie ID and tries to predict ratings based on how the other users have predicted the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, I attempted to build a model-based Collaborative Filtering movie recommendation sytem based on latent features from matrix factorization method called SVD. As it captures the underlying features driving the raw data, it can scale significantly better to massive datasets as well as make better recommendations based on user's tastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Airliquide.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "PyCharm (philippe_test)",
   "language": "python",
   "name": "pycharm-ada88a1a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}